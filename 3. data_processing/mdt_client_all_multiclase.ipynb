{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d96b9d34-c82b-4973-8a9e-67cb24767fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Librerias y Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c462651e-31ea-41e6-a25c-d0cd6f12a039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", True)\n",
    "spark.conf.set('spark.sql.shuffle.partitions', 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f3863d50-8884-42f4-8508-d55d49d44901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "### Librerías"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "### Funciones Ingenieria de datos"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "### Funciones de ingesta en RDS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "### Funciones de control de flujo de ingesta"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../../../../../04_utils/commons_functions_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dfdcc343-3dbd-468a-9906-64fc8f5baf39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../../../../04_utils/commons_functions_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "249d9e17-27d2-4085-92b5-96a4c9b3e9e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../../../../spigot/initial/global_parameter_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4e562ca1-6e27-40c4-9aff-043bb0b523b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from pyspark.sql import Window\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import plotly.express as px\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "from datetime import datetime, date\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f10973-bdc0-4645-bf65-f5facdd0a555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Carga de Fuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "236bf082-34d4-4f72-949c-f8e00e1de5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "int_pedidos_clientes = (spark.read.parquet(\"/Volumes/dbw_prod_aavanzada/db_tmp/files/pburbano/data/\")\n",
    "                                  .withColumn(\"fecha_pedido_dt\", F.to_date(F.col(\"fecha_pedido_dt\")))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51645178-5567-4660-b7f3-8b44be5dbd16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### MDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26549e5-67d3-4c10-a1e9-6ebff5b94216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# === 0. Base ===\n",
    "df = int_pedidos_clientes\n",
    "\n",
    "# === 1. Transformaciones iniciales ===\n",
    "# Convertir madurez_digital_cd a ordinal numérica\n",
    "df = df.withColumn(\n",
    "    \"madurez_digital_val\",\n",
    "    F.when(F.col(\"madurez_digital_cd\") == \"BAJA\", 1)\n",
    "     .when(F.col(\"madurez_digital_cd\") == \"MEDIA\", 2)\n",
    "     .when(F.col(\"madurez_digital_cd\") == \"ALTA\", 3)\n",
    "     .otherwise(None)\n",
    ")\n",
    "\n",
    "# Convertir estrellas_txt a numérica\n",
    "df = df.withColumn(\"estrellas_val\", F.col(\"estrellas_txt\").cast(\"int\"))\n",
    "\n",
    "# Convertir frecuencia_visitas_cd a cantidad de letras (número de días)\n",
    "df = df.withColumn(\"frecuencia_visitas_val\", F.length(F.col(\"frecuencia_visitas_cd\")))\n",
    "\n",
    "# === 2. Definición de ventanas ===\n",
    "w = Window.partitionBy(\"cliente_id\").orderBy(F.asc(\"fecha_pedido_dt\"))\n",
    "w_prev_all = w.rowsBetween(Window.unboundedPreceding, -1)\n",
    "w_recent = w.rowsBetween(-3, -1)\n",
    "\n",
    "# === 3. Crear canal siguiente y target multiclase ===\n",
    "df = df.withColumn(\"canal_siguiente\", F.lead(\"canal_pedido_cd\").over(w))\n",
    "df = df.filter(F.col(\"canal_siguiente\").isNotNull())\n",
    "\n",
    "# Target multiclase:\n",
    "# 0 = NO_DIGITAL → NO_DIGITAL\n",
    "# 1 = NO_DIGITAL → DIGITAL (adopta)\n",
    "# 2 = DIGITAL → DIGITAL (mantiene)\n",
    "# 3 = DIGITAL → NO_DIGITAL (abandona)\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"target\",\n",
    "    F.when((F.col(\"canal_pedido_cd\") != \"DIGITAL\") & (F.col(\"canal_siguiente\") != \"DIGITAL\"), 0)\n",
    "     .when((F.col(\"canal_pedido_cd\") != \"DIGITAL\") & (F.col(\"canal_siguiente\") == \"DIGITAL\"), 1)\n",
    "     .when((F.col(\"canal_pedido_cd\") == \"DIGITAL\") & (F.col(\"canal_siguiente\") == \"DIGITAL\"), 2)\n",
    "     .when((F.col(\"canal_pedido_cd\") == \"DIGITAL\") & (F.col(\"canal_siguiente\") != \"DIGITAL\"), 3)\n",
    ")\n",
    "\n",
    "# === 4. Variables de canal binarias (DIGITAL vs NO DIGITAL) ===\n",
    "df = (\n",
    "    df.withColumn(\"canal_previo\", F.lag(\"canal_pedido_cd\").over(w))\n",
    "      .withColumn(\"canal_actual\", F.col(\"canal_pedido_cd\"))\n",
    "      .withColumn(\"canal_actual_digital\", F.when(F.col(\"canal_actual\") == \"DIGITAL\", 1).otherwise(0))\n",
    "      .withColumn(\"canal_previo_digital\", F.when(F.col(\"canal_previo\") == \"DIGITAL\", 1).otherwise(0))\n",
    ")\n",
    "\n",
    "# === 5. Variables históricas ===\n",
    "df = (\n",
    "    df.withColumn(\"dias_desde_pedido_anterior\", F.datediff(\"fecha_pedido_dt\", F.lag(\"fecha_pedido_dt\").over(w)))\n",
    "      .withColumn(\"n_pedidos_previos\", F.row_number().over(w) - 1)\n",
    "      # Facturación\n",
    "      .withColumn(\"facturacion_prom_anterior\", F.avg(\"facturacion_usd_val\").over(w_prev_all))\n",
    "      .withColumn(\"facturacion_total_prev\", F.sum(\"facturacion_usd_val\").over(w_prev_all))\n",
    "      .withColumn(\"desviacion_facturacion\", F.stddev(\"facturacion_usd_val\").over(w_prev_all))\n",
    "      # Canal digital\n",
    "      .withColumn(\"uso_digital_prev\", F.sum(F.when(F.col(\"canal_pedido_cd\") == \"DIGITAL\", 1).otherwise(0)).over(w_prev_all))\n",
    "      .withColumn(\"uso_no_digital_prev\", F.col(\"n_pedidos_previos\") - F.col(\"uso_digital_prev\"))\n",
    "      .withColumn(\"prop_digital_prev\", \n",
    "                  F.when(F.col(\"n_pedidos_previos\") > 0,\n",
    "                         F.col(\"uso_digital_prev\") / F.col(\"n_pedidos_previos\")).otherwise(0))\n",
    "      .withColumn(\"prop_no_digital_prev\", \n",
    "                  F.when(F.col(\"n_pedidos_previos\") > 0,\n",
    "                         F.col(\"uso_no_digital_prev\") / F.col(\"n_pedidos_previos\")).otherwise(0))\n",
    "      # Frecuencia\n",
    "      .withColumn(\"dias_media_prev\", \n",
    "                  F.avg(F.datediff(\"fecha_pedido_dt\", F.lag(\"fecha_pedido_dt\").over(w))).over(w_prev_all))\n",
    "      .withColumn(\"dias_media_std\", \n",
    "                  F.stddev(F.datediff(\"fecha_pedido_dt\", F.lag(\"fecha_pedido_dt\").over(w))).over(w_prev_all))\n",
    ")\n",
    "\n",
    "# === 6. Variables recientes (últimos 3 pedidos) ===\n",
    "df = (\n",
    "    df.withColumn(\"facturacion_prom_reciente\", F.avg(\"facturacion_usd_val\").over(w_recent))\n",
    "      .withColumn(\"uso_digital_reciente\", F.avg(F.when(F.col(\"canal_pedido_cd\") == \"DIGITAL\", 1).otherwise(0)).over(w_recent))\n",
    "      .withColumn(\"uso_no_digital_reciente\", F.avg(F.when(F.col(\"canal_pedido_cd\") != \"DIGITAL\", 1).otherwise(0)).over(w_recent))\n",
    ")\n",
    "\n",
    "# === 7. Variables de materiales y cajas ===\n",
    "df = (\n",
    "    df\n",
    "      .withColumn(\"materiales_prom_prev\", F.avg(\"materiales_distintos_val\").over(w_prev_all))\n",
    "      .withColumn(\"materiales_total_prev\", F.sum(\"materiales_distintos_val\").over(w_prev_all))\n",
    "      .withColumn(\"cajas_fisicas_prom_prev\", F.avg(\"cajas_fisicas\").over(w_prev_all))\n",
    "      .withColumn(\"cajas_fisicas_total_prev\", F.sum(\"cajas_fisicas\").over(w_prev_all))\n",
    "      .withColumn(\"materiales_reciente\", F.avg(\"materiales_distintos_val\").over(w_recent))\n",
    "      .withColumn(\"cajas_fisicas_reciente\", F.avg(\"cajas_fisicas\").over(w_recent))\n",
    "      .withColumn(\"cajas_por_material\", \n",
    "                  F.when(F.col(\"materiales_distintos_val\") > 0, \n",
    "                         F.col(\"cajas_fisicas\") / F.col(\"materiales_distintos_val\"))\n",
    "                   .otherwise(0))\n",
    "      .withColumn(\"cajas_por_material_prev\", \n",
    "                  F.avg(F.when(F.col(\"materiales_distintos_val\") > 0, \n",
    "                               F.col(\"cajas_fisicas\") / F.col(\"materiales_distintos_val\"))\n",
    "                        .otherwise(0)).over(w_prev_all))\n",
    ")\n",
    "\n",
    "# === 8. Variables temporales ===\n",
    "df = (\n",
    "    df.withColumn(\"mes\", F.month(\"fecha_pedido_dt\"))\n",
    "      .withColumn(\"dia_semana\", F.dayofweek(\"fecha_pedido_dt\"))\n",
    "      .withColumn(\"es_fin_de_semana\", F.when(F.col(\"dia_semana\").isin(1, 7), 1).otherwise(0))\n",
    "      .withColumn(\"trimestre\", F.quarter(\"fecha_pedido_dt\"))\n",
    ")\n",
    "\n",
    "# === 9. Antigüedad ===\n",
    "df = df.withColumn(\n",
    "    \"antiguedad_dias\",\n",
    "    F.datediff(\"fecha_pedido_dt\", F.min(\"fecha_pedido_dt\").over(Window.partitionBy(\"cliente_id\")))\n",
    ")\n",
    "\n",
    "# === 10. Selección final de variables ===\n",
    "mdt = (\n",
    "    df.filter(F.col(\"n_pedidos_previos\") > 0)\n",
    "      .filter(F.col(\"target\").isNotNull())\n",
    "      .select(\n",
    "        # Identificadores\n",
    "        \"cliente_id\", \"pais_cd\", \"region_comercial_txt\", \"agencia_id\", \"ruta_id\",\n",
    "        \"tipo_cliente_cd\", \"madurez_digital_cd\", \"estrellas_txt\", \"frecuencia_visitas_cd\",\n",
    "        # Target multiclase\n",
    "        \"target\",\n",
    "        # Canal binario\n",
    "        \"canal_actual_digital\", \"canal_previo_digital\",\n",
    "        # Comportamiento histórico\n",
    "        \"facturacion_usd_val\", \"dias_desde_pedido_anterior\", \"n_pedidos_previos\",\n",
    "        \"facturacion_prom_anterior\", \"facturacion_total_prev\", \"desviacion_facturacion\",\n",
    "        \"uso_digital_prev\", \"uso_no_digital_prev\", \"prop_digital_prev\", \"prop_no_digital_prev\",\n",
    "        \"facturacion_prom_reciente\", \"uso_digital_reciente\", \"uso_no_digital_reciente\",\n",
    "        \"dias_media_prev\", \"dias_media_std\",\n",
    "        # Materiales y cajas\n",
    "        \"materiales_distintos_val\", \"materiales_prom_prev\", \"materiales_total_prev\", \"materiales_reciente\",\n",
    "        \"cajas_fisicas\", \"cajas_fisicas_prom_prev\", \"cajas_fisicas_total_prev\", \"cajas_fisicas_reciente\",\n",
    "        \"cajas_por_material\", \"cajas_por_material_prev\",\n",
    "        # Temporalidad\n",
    "        \"mes\", \"dia_semana\", \"es_fin_de_semana\", \"trimestre\",\n",
    "        \"antiguedad_dias\", \"fecha_pedido_dt\",\n",
    "        # Transformaciones\n",
    "        \"madurez_digital_val\", \"estrellas_val\", \"frecuencia_visitas_val\"\n",
    "      )\n",
    ")\n",
    "\n",
    "# === 11. Etiquetar periodo y limpiar ===\n",
    "fecha_corte = \"2024-03-01\"\n",
    "mdt = mdt.withColumn(\"periodo\", F.when(F.col(\"fecha_pedido_dt\") < fecha_corte, \"TRAIN\").otherwise(\"TEST\"))\n",
    "mdt = mdt.fillna(0)\n",
    "\n",
    "# === 12. Proporciones de adopción digital (basadas solo en TRAIN, sin leakage) ===\n",
    "prop_agencia = (\n",
    "    mdt.filter(\"periodo == 'TRAIN'\")\n",
    "       .groupBy(\"agencia_id\")\n",
    "       .agg(F.avg(F.when(F.col(\"target\").isin(2, 3), 1).otherwise(0)).alias(\"prop_digital_agencia\"))\n",
    ")\n",
    "prop_ruta = (\n",
    "    mdt.filter(\"periodo == 'TRAIN'\")\n",
    "       .groupBy(\"ruta_id\")\n",
    "       .agg(F.avg(F.when(F.col(\"target\").isin(2, 3), 1).otherwise(0)).alias(\"prop_digital_ruta\"))\n",
    ")\n",
    "\n",
    "# === 13. Join sin leakage ===\n",
    "mdt = mdt.join(prop_agencia, on=\"agencia_id\", how=\"left\")\n",
    "mdt = mdt.join(prop_ruta, on=\"ruta_id\", how=\"left\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6602459453049726,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "mdt_client_all_multiclase",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}